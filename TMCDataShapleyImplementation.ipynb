{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62334087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4582d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load input\n",
    "#600x1800x1800\n",
    "x = np.load('xAll0.npy')\n",
    "x2 = np.load('xAll1.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326758a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1800, 1800, 1)\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape(-1,1800,1800, 1)\n",
    "x2 = x2.reshape(-1,1800,1800, 1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c882aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 8) (600, 8)\n"
     ]
    }
   ],
   "source": [
    "y = np.load('y0.npy')\n",
    "y2 = np.load('y1.npy')\n",
    "#y = np.random.choice([0,1], size = (600, 8))\n",
    "print(y.shape,y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10024ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1800, 1800, 1)\n",
      "(150, 8)\n"
     ]
    }
   ],
   "source": [
    "valN = 150\n",
    "valx = x2[:valN, :, :, :]\n",
    "valy = y2[:valN,:]\n",
    "train_labels = y\n",
    "print(valx.shape)\n",
    "print(valy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0a0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(x=x, y = y, lst = [1,3,6]):\n",
    "    outx = []\n",
    "    outy = []\n",
    "    for i in lst:\n",
    "        outx.append(x[i])\n",
    "        outy.append(y[i])\n",
    "        \n",
    "    return np.asarray(outx), np.asarray(outy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3842df",
   "metadata": {},
   "outputs": [],
   "source": [
    "newx,newy = get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d047217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(reg = 3.4, lr = 5.3, model = (2, 600, 600)):\n",
    "    input_tensor = tf.keras.Input(shape=(1800,1800,1) )\n",
    "    r = 10**(-reg)\n",
    "    learningRate = 10**(-lr)\n",
    "    filter_size, FC1_size, FC2_size = model\n",
    "    input_tensor = tf.keras.Input(shape=(1800,1800,1) )\n",
    "    c1 = Conv2D(3, kernel_size=(filter_size, filter_size), activation='relu', \n",
    "                input_shape=(1800,1800,1), kernel_regularizer = tf.keras.regularizers.L2(r))(input_tensor) \n",
    "    l1 = tf.keras.layers.LayerNormalization()(c1)\n",
    "    mp1 = tf.keras.layers.MaxPool2D()(l1)\n",
    "    c2 = Conv2D(3, kernel_size=(filter_size, filter_size), activation='relu', \n",
    "                kernel_regularizer = tf.keras.regularizers.L2(r))(mp1)\n",
    "    l2 = tf.keras.layers.LayerNormalization()(c2)\n",
    "    mp2 = tf.keras.layers.MaxPool2D()(l2)\n",
    "    c3 = Conv2D(3, kernel_size=(filter_size, filter_size), activation='relu', \n",
    "                kernel_regularizer = tf.keras.regularizers.L2(r))(mp2)\n",
    "    l3 = tf.keras.layers.LayerNormalization()(c3)\n",
    "    mp3 = tf.keras.layers.MaxPool2D()(l3)\n",
    "    c4 = Conv2D(3, kernel_size=(filter_size, filter_size), activation='relu', \n",
    "    kernel_regularizer = tf.keras.regularizers.L2(r))(mp3)\n",
    "    l4 = tf.keras.layers.LayerNormalization()(c4)\n",
    "    mp4 = tf.keras.layers.MaxPool2D()(l4)\n",
    "    c5 = Conv2D(3, kernel_size=(filter_size, filter_size), activation='relu', \n",
    "    kernel_regularizer = tf.keras.regularizers.L2(r))(mp4)\n",
    "    l5 = tf.keras.layers.LayerNormalization()(c5)\n",
    "    mp5 = tf.keras.layers.MaxPool2D()(l5)\n",
    "    c6 = Conv2D(3, kernel_size=(filter_size, filter_size), activation='relu', \n",
    "    kernel_regularizer = tf.keras.regularizers.L2(r))(mp5)\n",
    "    l6 = tf.keras.layers.LayerNormalization()(c6)\n",
    "    mp6 = tf.keras.layers.MaxPool2D()(l6)\n",
    "    head_out = Flatten()(mp6)\n",
    "    FC1 = Dense(FC1_size, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(r))(head_out)\n",
    "    l7 = tf.keras.layers.LayerNormalization()(FC1)\n",
    "    FC2 = Dense(FC2_size, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(r))(l7)\n",
    "    predictions = Dense(8, activation = 'sigmoid', kernel_regularizer = tf.keras.regularizers.L2(r)) (FC2)\n",
    "    model = Model(inputs=input_tensor,outputs=predictions)\n",
    "    #run\n",
    "    model.compile(loss= categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate=learningRate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6edaebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_examples=newx,train_labels=newy, validation_data = (valx,valy), model = None):\n",
    "    if model == None:\n",
    "        model = gen_model()\n",
    "    numEpochs = 1\n",
    "    history = model.fit(train_examples,train_labels, validation_data = (valx,valy),epochs = 1)\n",
    "    return history.history['val_loss'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68688708",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f5c2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtcDataShapley(x=x, y = y,valx = valx, valy= valy, N = 5, L=25):\n",
    "    for i in range(N):\n",
    "        results = {}\n",
    "        loss = 100\n",
    "        lst = []\n",
    "        model = gen_model()\n",
    "        while loss > 3 and len(lst)<L:\n",
    "            k= np.random.randint(0,600)\n",
    "            while k in lst:\n",
    "                k= np.random.randint(0,600)\n",
    "            lst.append(k)\n",
    "            print('running with samples '+str(lst))\n",
    "            newx,newy = get_train(x,y,lst)\n",
    "            newloss = train(model= model)\n",
    "            if len(lst)>1:\n",
    "                if k not in results:\n",
    "                    results[k] = []\n",
    "                results[k].append(loss-newloss)\n",
    "            loss = newloss\n",
    "            if len(lst)%4==0:\n",
    "                print('\\nLIST HAS '+str(len(lst))+' SAMPLES\\n')\n",
    "        t = time.time()\n",
    "        rdf = pd.DataFrame(results)\n",
    "        rdf.to_csv('shapley/'+str(t)+'.csv')\n",
    "        print('\\nSAVED RESULTS for loop\\n'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9427302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with samples [515]\n",
      "1/1 [==============================] - 29s 29s/step - loss: 3.2138 - accuracy: 0.3333 - val_loss: 3.5543 - val_accuracy: 0.1133\n",
      "running with samples [515, 589]\n",
      "1/1 [==============================] - 52s 52s/step - loss: 3.1712 - accuracy: 0.6667 - val_loss: 3.5459 - val_accuracy: 0.1200\n",
      "running with samples [515, 589, 176]\n",
      "1/1 [==============================] - 57s 57s/step - loss: 3.1178 - accuracy: 0.6667 - val_loss: 3.5384 - val_accuracy: 0.1267\n",
      "running with samples [515, 589, 176, 24]\n",
      "1/1 [==============================] - 57s 57s/step - loss: 3.0739 - accuracy: 0.6667 - val_loss: 3.5314 - val_accuracy: 0.1267\n",
      "\n",
      "LIST HAS 4 SAMPLES\n",
      "\n",
      "running with samples [515, 589, 176, 24, 566]\n",
      "1/1 [==============================] - 56s 56s/step - loss: 3.0354 - accuracy: 0.6667 - val_loss: 3.5232 - val_accuracy: 0.1267\n",
      "running with samples [515, 589, 176, 24, 566, 520]\n",
      "1/1 [==============================] - 54s 54s/step - loss: 2.9988 - accuracy: 0.6667 - val_loss: 3.5161 - val_accuracy: 0.1267\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203]\n",
      "1/1 [==============================] - 55s 55s/step - loss: 2.9648 - accuracy: 0.6667 - val_loss: 3.5094 - val_accuracy: 0.1200\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15]\n",
      "1/1 [==============================] - 55s 55s/step - loss: 2.9336 - accuracy: 0.6667 - val_loss: 3.5033 - val_accuracy: 0.1200\n",
      "\n",
      "LIST HAS 8 SAMPLES\n",
      "\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34]\n",
      "1/1 [==============================] - 55s 55s/step - loss: 2.9029 - accuracy: 0.6667 - val_loss: 3.4977 - val_accuracy: 0.1267\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369]\n",
      "1/1 [==============================] - 56s 56s/step - loss: 2.8738 - accuracy: 1.0000 - val_loss: 3.4920 - val_accuracy: 0.1267\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348]\n",
      "1/1 [==============================] - 55s 55s/step - loss: 2.8466 - accuracy: 1.0000 - val_loss: 3.4864 - val_accuracy: 0.1267\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415]\n",
      "1/1 [==============================] - 57s 57s/step - loss: 2.8206 - accuracy: 1.0000 - val_loss: 3.4809 - val_accuracy: 0.1267\n",
      "\n",
      "LIST HAS 12 SAMPLES\n",
      "\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96]\n",
      "1/1 [==============================] - 56s 56s/step - loss: 2.7958 - accuracy: 1.0000 - val_loss: 3.4760 - val_accuracy: 0.1267\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436]\n",
      "1/1 [==============================] - 54s 54s/step - loss: 2.7722 - accuracy: 1.0000 - val_loss: 3.4711 - val_accuracy: 0.1400\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478]\n",
      "1/1 [==============================] - 57s 57s/step - loss: 2.6830 - accuracy: 1.0000 - val_loss: 3.4527 - val_accuracy: 0.1600\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478, 306, 207, 147, 31]\n",
      "1/1 [==============================] - 55s 55s/step - loss: 2.6609 - accuracy: 1.0000 - val_loss: 3.4485 - val_accuracy: 0.1600\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478, 306, 207, 147, 31, 261]\n",
      "1/1 [==============================] - 60s 60s/step - loss: 2.6394 - accuracy: 1.0000 - val_loss: 3.4444 - val_accuracy: 0.1667\n",
      "\n",
      "LIST HAS 20 SAMPLES\n",
      "\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478, 306, 207, 147, 31, 261, 194]\n",
      "1/1 [==============================] - 58s 58s/step - loss: 2.6183 - accuracy: 1.0000 - val_loss: 3.4405 - val_accuracy: 0.1667\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478, 306, 207, 147, 31, 261, 194, 324]\n",
      "1/1 [==============================] - 58s 58s/step - loss: 2.5976 - accuracy: 1.0000 - val_loss: 3.4365 - val_accuracy: 0.1733\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478, 306, 207, 147, 31, 261, 194, 324, 199]\n",
      "1/1 [==============================] - 58s 58s/step - loss: 2.5769 - accuracy: 1.0000 - val_loss: 3.4326 - val_accuracy: 0.1800\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478, 306, 207, 147, 31, 261, 194, 324, 199, 384]\n",
      "1/1 [==============================] - 62s 62s/step - loss: 2.5561 - accuracy: 1.0000 - val_loss: 3.4288 - val_accuracy: 0.1867\n",
      "\n",
      "LIST HAS 24 SAMPLES\n",
      "\n",
      "running with samples [515, 589, 176, 24, 566, 520, 203, 15, 34, 369, 348, 415, 96, 436, 478, 306, 207, 147, 31, 261, 194, 324, 199, 384, 77]\n",
      "1/1 [==============================] - 58s 58s/step - loss: 2.5352 - accuracy: 1.0000 - val_loss: 3.4251 - val_accuracy: 0.1867\n",
      "\n",
      "SAVED RESULTS for loop\n",
      "0\n",
      "running with samples [355]\n",
      "1/1 [==============================] - 56s 56s/step - loss: 3.6418 - accuracy: 0.0000e+00 - val_loss: 3.6588 - val_accuracy: 0.1200\n",
      "running with samples [355, 584]\n",
      "1/1 [==============================] - 56s 56s/step - loss: 3.6390 - accuracy: 0.0000e+00 - val_loss: 3.6537 - val_accuracy: 0.1133\n",
      "running with samples [355, 584, 381]\n",
      "1/1 [==============================] - 58s 58s/step - loss: 3.5031 - accuracy: 0.0000e+00 - val_loss: 3.6381 - val_accuracy: 0.1200\n",
      "running with samples [355, 584, 381, 316]\n",
      "1/1 [==============================] - 56s 56s/step - loss: 3.4560 - accuracy: 0.0000e+00 - val_loss: 3.6825 - val_accuracy: 0.1133\n",
      "\n",
      "LIST HAS 4 SAMPLES\n",
      "\n",
      "running with samples [355, 584, 381, 316, 376]\n",
      "1/1 [==============================] - 58s 58s/step - loss: 3.4157 - accuracy: 0.0000e+00 - val_loss: 3.6844 - val_accuracy: 0.1200\n",
      "running with samples [355, 584, 381, 316, 376, 126]\n",
      "1/1 [==============================] - 63s 63s/step - loss: 3.3615 - accuracy: 0.0000e+00 - val_loss: 3.6774 - val_accuracy: 0.1133\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190]\n",
      "1/1 [==============================] - 57s 57s/step - loss: 3.3187 - accuracy: 0.0000e+00 - val_loss: 3.6679 - val_accuracy: 0.1200\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370]\n",
      "1/1 [==============================] - 59s 59s/step - loss: 3.2685 - accuracy: 0.0000e+00 - val_loss: 3.6542 - val_accuracy: 0.1200\n",
      "\n",
      "LIST HAS 8 SAMPLES\n",
      "\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146]\n",
      "1/1 [==============================] - 58s 58s/step - loss: 3.2207 - accuracy: 0.0000e+00 - val_loss: 3.6422 - val_accuracy: 0.1133\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388]\n",
      "1/1 [==============================] - 50s 50s/step - loss: 3.1804 - accuracy: 0.0000e+00 - val_loss: 3.6356 - val_accuracy: 0.1133\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 3.1389 - accuracy: 0.0000e+00 - val_loss: 3.6323 - val_accuracy: 0.1200\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 3.1001 - accuracy: 0.0000e+00 - val_loss: 3.6272 - val_accuracy: 0.1267\n",
      "\n",
      "LIST HAS 12 SAMPLES\n",
      "\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 3.0649 - accuracy: 0.0000e+00 - val_loss: 3.6200 - val_accuracy: 0.1267\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573, 236]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 3.0307 - accuracy: 0.0000e+00 - val_loss: 3.6125 - val_accuracy: 0.1267\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573, 236, 453]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 2.9990 - accuracy: 0.0000e+00 - val_loss: 3.6060 - val_accuracy: 0.1267\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573, 236, 453, 86]\n",
      "1/1 [==============================] - 44s 44s/step - loss: 2.9695 - accuracy: 0.0000e+00 - val_loss: 3.6001 - val_accuracy: 0.1267\n",
      "\n",
      "LIST HAS 16 SAMPLES\n",
      "\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573, 236, 453, 86, 555]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 2.9422 - accuracy: 0.0000e+00 - val_loss: 3.5949 - val_accuracy: 0.1267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573, 236, 453, 86, 555, 525]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 2.8099 - accuracy: 0.6667 - val_loss: 3.5625 - val_accuracy: 0.1200\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573, 236, 453, 86, 555, 525, 321, 479, 330, 432, 62, 285]\n",
      "1/1 [==============================] - 44s 44s/step - loss: 2.7915 - accuracy: 0.6667 - val_loss: 3.5583 - val_accuracy: 0.1200\n",
      "\n",
      "LIST HAS 24 SAMPLES\n",
      "\n",
      "running with samples [355, 584, 381, 316, 376, 126, 190, 370, 146, 388, 332, 227, 573, 236, 453, 86, 555, 525, 321, 479, 330, 432, 62, 285, 314]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 2.7739 - accuracy: 0.6667 - val_loss: 3.5535 - val_accuracy: 0.1267\n",
      "\n",
      "SAVED RESULTS for loop\n",
      "1\n",
      "running with samples [235]\n",
      "1/1 [==============================] - 45s 45s/step - loss: 3.7128 - accuracy: 0.0000e+00 - val_loss: 3.3894 - val_accuracy: 0.2400\n",
      "running with samples [235, 23]\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6327 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "mtcDataShapley()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f5911d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47b1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
